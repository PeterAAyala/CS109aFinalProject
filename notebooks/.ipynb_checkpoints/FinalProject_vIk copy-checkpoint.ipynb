{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Data Processing and EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import json\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from random import *\n",
    "from math import log\n",
    "from pandas.io.json import json_normalize\n",
    "import copy\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "from scipy.stats.stats import pearsonr   \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('dataset/business.json') as f:\n",
    "    business_data = [json.loads(line) for line in f]\n",
    "with open('dataset/user.json') as f:\n",
    "    user_data = [json.loads(line) for line in f]  \n",
    "# preprocessed review file with reviews only for restaurants \n",
    "with open('dataset/restaurant_reviews_trimmed.json') as f:\n",
    "    review_data = [json.loads(line) for line in f]\n",
    "\n",
    "# pull just restaurant data from business data\n",
    "restaurant_data = [x for x in business_data if 'Restaurants' in x['categories']]\n",
    "\n",
    "# convert array to list\n",
    "restaurant_reviews = review_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Create a Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting global averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7118346541447185\n"
     ]
    }
   ],
   "source": [
    "user_total = [x['average_stars'] for x in user_data]\n",
    "global_user_average = sum(user_total)/len(user_total)\n",
    "print (global_user_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.461104760428574\n"
     ]
    }
   ],
   "source": [
    "restaurant_total = [x['stars'] for x in restaurant_data]\n",
    "global_restaurant_average = sum(restaurant_total)/len(restaurant_total)\n",
    "print (global_restaurant_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.702161161664101\n"
     ]
    }
   ],
   "source": [
    "reviews_total = [x['stars'] for x in restaurant_reviews]\n",
    "global_review_average = sum(reviews_total)/len(reviews_total)\n",
    "print (global_review_average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Global Averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "restaurant_dict = {}\n",
    "for item in restaurant_data:\n",
    "    restaurant_id = item['business_id']\n",
    "    restaurant_dict[restaurant_id] = item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for easy lookup based on user id\n",
    "user_dict = {}\n",
    "for item in user_data:\n",
    "    user_id = item['user_id']\n",
    "    user_dict[user_id] = item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_deviations = {}\n",
    "for item in user_data:\n",
    "    user_id = item['user_id']\n",
    "    user_deviations[user_id] = item['average_stars'] - global_user_average\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "restaurant_deviations = {}\n",
    "for item in restaurant_data:\n",
    "    rest_id = item['business_id']\n",
    "    restaurant_deviations[rest_id] = item['stars'] - global_restaurant_average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Rating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#getting a random evaluation set of 20000\n",
    "evaluation_set = np.random.choice(restaurant_reviews, size = 20000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluation_df = pd.DataFrame(list(evaluation_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluation_df = evaluation_df.drop(['cool', 'date', 'funny','text','useful'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def baseline(user_id, business_id):\n",
    "    pred = global_review_average + user_deviations[user_id] + restaurant_deviations[business_id]\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluation_df['baseline_pred'] = [baseline(x,y) for (x,y) in zip(evaluation_df['user_id'],evaluation_df['business_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.26203188939\n"
     ]
    }
   ],
   "source": [
    "score = metrics.mean_squared_error(evaluation_df['stars'], evaluation_df['baseline_pred'])\n",
    "print (score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del evaluation_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Create a Regularized Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating training, validating, and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# take 100000 reviews as sample\n",
    "data_array = (np.random.choice(restaurant_reviews, size = 100000))\n",
    "data_set = list(data_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find all categories for one-hot encoding purposes\n",
    "from collections import Counter\n",
    "all_categories = []\n",
    "for r in restaurant_data:\n",
    "    if 'Restaurants' in r['categories']:\n",
    "        for c in r['categories']:\n",
    "            all_categories.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# take 150 most popular categories\n",
    "counts = list (Counter(all_categories).items())\n",
    "counts.sort(key=lambda x: x[1], reverse = True)\n",
    "most_popular = [x[0] for x in counts[:150]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "expanded_reviews = copy.deepcopy(data_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add business and user info\n",
    "\n",
    "for review in expanded_reviews:\n",
    "    #print (review)\n",
    "    restaurant = review['business_id']\n",
    "    user = review['user_id']\n",
    "    restaurant_info = restaurant_dict[restaurant]\n",
    "    #print (restaurant_info)\n",
    "    user_info = user_dict[user]\n",
    "    for attribute in restaurant_info:\n",
    "        #print (attribute)\n",
    "        if attribute not in ['is_open', 'latitude','longitude','name','business_id',\n",
    "                             'neighborhood','address','city','postal_code','hours']:\n",
    "            if attribute == 'categories':\n",
    "                for c in most_popular:\n",
    "                    if c in restaurant_info[attribute]:\n",
    "                        review['R_' +  c] = 1\n",
    "                    else:\n",
    "                        review['R_' +  c] = 0\n",
    "            else:         \n",
    "                review['R_' + attribute] = restaurant_info[attribute]\n",
    "    for attribute in user_info:\n",
    "        if attribute not in ['user_id','name']:   \n",
    "            if attribute == 'friends':\n",
    "                review['U_friends'] = len(user_info[attribute])\n",
    "            elif attribute == 'yelping_since':\n",
    "                review['U_yelping_since'] = user_info[attribute][:4]\n",
    "            elif attribute == 'elite':\n",
    "                if user_info[attribute]:\n",
    "                    review['U_elite'] = True\n",
    "                else:\n",
    "                    review['U_elite'] = False        \n",
    "            else:\n",
    "                review['U_' + attribute] = user_info[attribute] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create pandas dataframe\n",
    "flatframe = json_normalize(expanded_reviews)\n",
    "flatframe = flatframe.drop(['text','useful','funny','cool','date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# change user since\n",
    "flatframe['U_years_yelping'] = [2015 - int(x) for x in flatframe['U_yelping_since']]\n",
    "flatframe.drop(['U_yelping_since'],axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop ids\n",
    "flatframe = flatframe.drop(['business_id', 'review_id', 'user_id'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#one hot encode state\n",
    "flatframe = pd.get_dummies(flatframe, columns = ['R_state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train test split\n",
    "msk = np.random.rand(len(flatframe)) < 0.5\n",
    "data_train = flatframe[msk]\n",
    "data_test = flatframe[~msk]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'no'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-9d50ddf437e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/PeterAyala/anaconda/lib/python3.6/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0mn_jobs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m         X, y = check_X_y(X, y, accept_sparse=['csr', 'csc', 'coo'],\n\u001b[0;32m--> 512\u001b[0;31m                          y_numeric=True, multi_output=True)\n\u001b[0m\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/PeterAyala/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    519\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[1;32m    520\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[1;32m    522\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m/Users/PeterAyala/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0;31m# make sure we actually converted to numeric:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"O\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'no'"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "Xtrain = data_train.drop(['stars'], axis = 1)\n",
    "ytrain = data_train['stars']\n",
    "Xtest = data_test.drop(['stars'], axis = 1)\n",
    "ytest = data_test['stars']\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ypred = model.predict(Xtrain)\n",
    "ypred_test = model.predict(Xtest)\n",
    "predround = [int(round(x)) for x in ypred]\n",
    "print (\"The accuracy score of the linear model on the train set is {}\"\n",
    "       .format(metrics.accuracy_score(ytrain, predround)))\n",
    "predround_test = [int(round(x)) for x in ypred_test]\n",
    "print (\"The accuracy score of the linear model on the test set is {}\"\n",
    "       .format(metrics.accuracy_score(ytest, predround_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_ridge = RidgeCV().fit(Xtrain, ytrain)\n",
    "ridge_ypred = model_ridge.predict(Xtrain)\n",
    "ridge_ypred_round = [int(round(x)) for x in ridge_ypred]\n",
    "ridge_ypred_test = model_ridge.predict(Xtest)\n",
    "ridge_ypred_test_round = [int(round(x)) for x in ridge_ypred_test]\n",
    "\n",
    "\n",
    "print (\"The accuracy score of the ridge model on the train set is {}\"\n",
    "       .format(metrics.accuracy_score(ytrain, ridge_ypred_round)))\n",
    "print (\"The accuracy score of the ridge model on the test set is {}\"\n",
    "       .format(metrics.accuracy_score(ytest, ridge_ypred_test_round)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_lasso = LassoCV().fit(Xtrain, ytrain)\n",
    "\n",
    "\n",
    "lasso_ypred = model_lasso.predict(Xtrain)\n",
    "lasso_ypred_round = [int(round(x)) for x in lasso_ypred]\n",
    "lasso_ypred_test = model_lasso.predict(Xtest)\n",
    "lasso_ypred_test_round = [int(round(x)) for x in lasso_ypred_test]\n",
    "\n",
    "print (\"The accuracy score of the lasso model on the train set is {}\"\n",
    "       .format(metrics.accuracy_score(ytrain, lasso_ypred_round)))\n",
    "print (\"The accuracy score of the lasso model on the test set is {}\"\n",
    "       .format(metrics.accuracy_score(ytest, lasso_ypred_test_round)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_df = flatframe[['stars', 'business_id', 'user_id']]\n",
    "\n",
    "train_base = base_df[msk]\n",
    "test_base = base_df[~msk]\n",
    "\n",
    "base_pred = [baseline(x,y) for x,y in zip(train_base['user_id'],train_base['business_id'])]\n",
    "base_pred_test = [baseline(x,y) for x,y in zip(test_base['user_id'],test_base['business_id'])]\n",
    "\n",
    "print (\"The accuracy score of the baseline model on the train set is {}\"\n",
    "       .format(metrics.accuracy_score(ytrain, base_pred)))\n",
    "print (\"The accuracy score of the baseline model on the test set is {}\"\n",
    "       .format(metrics.accuracy_score(ytest, base_pred_test)))\n",
    "\n",
    "\n",
    "base_pred_2 = [baseline2(x,y) for x,y in zip(train_base['user_id'],train_base['business_id'])]\n",
    "base_pred_test_2 = [baseline2(x,y) for x,y in zip(test_base['user_id'],test_base['business_id'])]\n",
    "print (\"The accuracy score of the baseline2 model on the train set is {}\"\n",
    "       .format(metrics.accuracy_score(ytrain, base_pred_2)))\n",
    "print (\"The accuracy score of the baseline2 model on the test set is {}\"\n",
    "       .format(metrics.accuracy_score(ytest, base_pred_test_2)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
