{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "hide": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import json\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import LassoCV\n",
    "from random import *\n",
    "from math import log\n",
    "import json\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "with open('dataset/good_reviews.json') as f:\n",
    "    good_reviews = [json.loads(line) for line in f]\n",
    "with open('dataset/business.json') as f:\n",
    "    business_data = [json.loads(line) for line in f]\n",
    "with open('dataset/user.json') as f:\n",
    "    user_data = [json.loads(line) for line in f]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_reviews = good_reviews[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted_user_reviews = sorted(good_reviews, key = lambda x: x['user_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the train, valid, and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For matrix factorization, we faced several unique issues:\n",
    "\n",
    "* Matrix Sparsity: Our data was incredibly sparse. Originally, our matrix had <5% non zero values. However, single-value decomposition doesn't work on sparse matrices. Thus, we had to reduce our set of restaurant reviews significantly, to only include restaurants and user with over 100 reviews. We also used alternating least squares to find the latent factor vectors, as opposed to SVD.\n",
    "\n",
    "* Runtime: The process of learning the latent was incredibly time intensive. Thus, we limited our model to 4 latent factors. \n",
    "\n",
    "* Size of model: Our train set included 1252 users and 3484 restaurants, Thus, we only computed latent factors for 1252 users and 3484 items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set = []\n",
    "valid_set = []\n",
    "test_set = []\n",
    "for i,x in enumerate(sorted_user_reviews[:100000]):\n",
    "    short = {k: x[k] for k in ['business_id', 'stars', 'user_id']}\n",
    "    if i % 3 == 0:\n",
    "        train_set.append(short)\n",
    "    elif i % 3 == 1:\n",
    "        valid_set.append(short)  \n",
    "    else:\n",
    "        test_set.append(short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train_set)\n",
    "valid_df = pd.DataFrame(valid_set)\n",
    "test_df = pd.DataFrame(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALS Matrix Factorization with 4 Factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making the dataset more manageable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trimmed_train = train_df[:5000]\n",
    "trimmed_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the user and item deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_data = [x for x in business_data if 'Restaurants' in x['categories']]\n",
    "\n",
    "good_restaurants_info = [x for x in restaurant_data if x['review_count'] >= 100]\n",
    "restaurant_dict = {x['business_id']: x['stars'] for x in restaurant_data}\n",
    "good_user_info = [x for x in user_data if x['review_count'] >= 100]\n",
    "user_dict = {x['user_id']: x['average_stars'] for x in good_user_info}\n",
    "\n",
    "global_review_average = sum(trimmed_train['stars'].values)/len(trimmed_train)\n",
    "user_global_average = sum(user_dict.values())/len(user_dict)\n",
    "rest_global_average = sum(restaurant_dict.values())/len(restaurant_dict)\n",
    "user_deviations = {x: user_dict[x] - user_global_average for x in user_dict}\n",
    "restaurant_deviations = {x: restaurant_dict[x] - rest_global_average for x in restaurant_dict}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making the dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wanted to create 2 dictionaries:\n",
    "* ratings_by_restaurant_train_trimmed: This dictionary has key = restaurant and value = all the reviews given to the restaurant\n",
    "* ratings_by_user_train_trimmed: This dictionary has key = user and value = all the reviews that the user has given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratings_by_restaurant_train_trimmed = {}\n",
    "ratings_by_user_train_trimmed = {}\n",
    "\n",
    "for i in range(len(trimmed_train)):\n",
    "    row = trimmed_train.iloc[i]\n",
    "    bus_id = row[0]\n",
    "    stars = row[1]\n",
    "    user_id = row[2]\n",
    "    if bus_id not in ratings_by_restaurant_train_trimmed:\n",
    "        ratings_by_restaurant_train_trimmed[bus_id] = {user_id : stars}\n",
    "    else:\n",
    "        ratings_by_restaurant_train_trimmed[bus_id][user_id] = stars\n",
    "        \n",
    "    if user_id not in ratings_by_user_train_trimmed:\n",
    "        ratings_by_user_train_trimmed[user_id] = {bus_id : stars}\n",
    "    else:\n",
    "        ratings_by_user_train_trimmed[user_id][bus_id] = stars\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing for Alternating Least Squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the random dummy vectors to initial our p and q vectors, set lambda the regularization parameter equal to 0.1, and decide our tuning vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create dummy vectors for p and q at start\n",
    "import random\n",
    "q_item = {}\n",
    "p_user = {}\n",
    "#just random\n",
    "for r in ratings_by_restaurant_train_trimmed:\n",
    "    q_item[r] = [randrange(1,10)/10 for _ in range(4)]\n",
    "for u in ratings_by_user_train_trimmed:\n",
    "    p_user[u] = [randrange(1,10)/10 for _ in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tuning_vectors = []\n",
    "for a in range(1,10):\n",
    "    for b in range(1,10):\n",
    "        for c in range(1,10):\n",
    "            for d in range(1,10):\n",
    "                tuning_vectors.append([a/10, b/10, c/10, d/10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lmda = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining tuning functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_sum_user_4(tuning_vector, user):\n",
    "    user_vector = tuning_vector\n",
    "    uv_mag = np.linalg.norm(user_vector)\n",
    "    summation = 0\n",
    "    #iterate through restaurants that user has rated\n",
    "    for restaurant in ratings_by_user_train_trimmed[user]:\n",
    "        #get the restaurants vector\n",
    "        item_vector = q_item[restaurant]\n",
    "        rv_mag = np.linalg.norm(item_vector)\n",
    "        term = np.dot(user_vector, item_vector) \n",
    "        #get the biases\n",
    "        user_dev = user_deviations[user]\n",
    "        item_dev = restaurant_deviations[restaurant]\n",
    "        #follow the MLE equation\n",
    "        error = (ratings_by_user_train_trimmed[user][restaurant] - global_review_average - term - user_dev - item_dev) ** 2 \n",
    "        + lmda * (uv_mag **2 + rv_mag ** 2 + user_dev ** 2 + item_dev ** 2)\n",
    "        summation += error\n",
    "    return summation\n",
    "\n",
    "\n",
    "def minimize_user_vectors_4():\n",
    "    convergence = 0\n",
    "    #iterate though all the the users\n",
    "    for user in ratings_by_user_train_trimmed:\n",
    "        #list of tuples (tuning vector, sum)\n",
    "        tuning_sums = []\n",
    "        #iterate though the vectors to find the best one for the user\n",
    "        for tuning_vector in tuning_vectors:\n",
    "            tuning_sum = calculate_sum_user_4(tuning_vector, user)\n",
    "            tuning_sums.append((tuning_vector, tuning_sum))\n",
    "        #get the vector with the lowest sum\n",
    "        best = (min(tuning_sums, key = lambda x: x[1])[0])\n",
    "        #get the difference between the current vector and the best vector\n",
    "        difference = abs(best[0] - p_user[user][0]) + abs(best[1] - p_user[user][1])\n",
    "        + abs(best[2] - q_item[item][2]) + abs(best[3] - q_item[item][3])\n",
    "        #set vector to best\n",
    "        p_user[user] = best\n",
    "        #add the difference to the convergence\n",
    "        convergence += difference\n",
    "    return convergence\n",
    "                     \n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_sum_item_4(tuning_vector, item):\n",
    "    item_vector = tuning_vector\n",
    "    rv_mag = np.linalg.norm(item_vector)\n",
    "    summation = 0\n",
    "    for user in ratings_by_restaurant_train_trimmed[item]:\n",
    "        user_vector = p_user[user]\n",
    "        uv_mag = np.linalg.norm(user_vector)\n",
    "        term = np.dot(item_vector, user_vector) \n",
    "        user_dev = user_deviations[user]\n",
    "        item_dev = restaurant_deviations[item]\n",
    "        error = (ratings_by_restaurant_train_trimmed[item][user] - global_review_average - user_dev - item_dev - term) ** 2 \n",
    "        + lmda * (uv_mag **2 + rv_mag ** 2 + user_dev ** 2 + item_dev ** 2)\n",
    "        #print ('error', error)\n",
    "        summation += error\n",
    "    return summation\n",
    "\n",
    "\n",
    "def minimize_item_vectors_4():\n",
    "    #print ('minimizing item vectors')\n",
    "    convergence = 0\n",
    "    #iterate though all the the users\n",
    "    for item in ratings_by_restaurant_train_trimmed:\n",
    "        #list with tuple (vector, corresponding sum)\n",
    "        tuning_sums = []\n",
    "        #iterate though the vectors to find the best one for the user\n",
    "        for tuning_vector in tuning_vectors:\n",
    "            tuning_sum = calculate_sum_item_4(tuning_vector, item)\n",
    "            tuning_sums.append((tuning_vector, tuning_sum))\n",
    "        best = (min(tuning_sums, key = lambda x: x[1])[0])\n",
    "        #print ('best', best)\n",
    "        #get the difference between the current vector and the best vector\n",
    "        difference = abs(best[0] - q_item[item][0]) + abs(best[1] - q_item[item][1]) \n",
    "        + abs(best[2] - q_item[item][2]) + abs(best[3] - q_item[item][3])\n",
    "        #set vector to best\n",
    "        #print ('best',best)\n",
    "        q_item[item] = best\n",
    "        convergence += difference\n",
    "        #print ('convergence value', convergence)\n",
    "    return convergence\n",
    "                     \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ALS_4():\n",
    "    print ('minimizing user vectors')\n",
    "    conv = minimize_user_vectors_4()\n",
    "    print (conv)\n",
    "    #whil vectors have not converged\n",
    "    while conv > 10: \n",
    "        for _ in range(1000):\n",
    "            print ('minimizing item vectors')\n",
    "            conv = minimize_item_vectors_4()\n",
    "            print (conv)\n",
    "            print ('minimizing user vectors')\n",
    "            conv = minimize_user_vectors_4()\n",
    "            print (conv)\n",
    "                \n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimizing user vectors\n",
      "948.2000000000005\n",
      "minimizing item vectors\n",
      "2680.099999999998\n",
      "minimizing user vectors\n",
      "206.19999999999956\n",
      "minimizing item vectors\n",
      "359.6999999999987\n",
      "minimizing user vectors\n",
      "90.89999999999995\n",
      "minimizing item vectors\n",
      "196.79999999999959\n",
      "minimizing user vectors\n",
      "32.40000000000004\n",
      "minimizing item vectors\n",
      "144.0\n",
      "minimizing user vectors\n",
      "21.800000000000004\n",
      "minimizing item vectors\n",
      "86.80000000000001\n",
      "minimizing user vectors\n",
      "12.399999999999997\n",
      "minimizing item vectors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-40-cf41abbe0d88>\", line 1, in <module>\n",
      "    ALS_4()\n",
      "  File \"<ipython-input-39-7b846cbe4343>\", line 8, in ALS_4\n",
      "    conv = minimize_item_vectors_4()\n",
      "  File \"<ipython-input-35-4e7e92481872>\", line 27, in minimize_item_vectors_4\n",
      "    tuning_sum = calculate_sum_item_4(tuning_vector, item)\n",
      "  File \"<ipython-input-35-4e7e92481872>\", line 3, in calculate_sum_item_4\n",
      "    rv_mag = np.linalg.norm(item_vector)\n",
      "  File \"/anaconda/lib/python3.6/site-packages/numpy/linalg/linalg.py\", line 2022, in norm\n",
      "    def norm(x, ord=None, axis=None, keepdims=False):\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 1821, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/anaconda/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/anaconda/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/anaconda/lib/python3.6/inspect.py\", line 1453, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/anaconda/lib/python3.6/inspect.py\", line 1411, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/anaconda/lib/python3.6/inspect.py\", line 666, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/anaconda/lib/python3.6/inspect.py\", line 695, in getmodule\n",
      "    file = getabsfile(object, _filename)\n",
      "  File \"/anaconda/lib/python3.6/inspect.py\", line 679, in getabsfile\n",
      "    return os.path.normcase(os.path.abspath(_filename))\n",
      "  File \"/anaconda/lib/python3.6/posixpath.py\", line 374, in abspath\n",
      "    cwd = os.getcwd()\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "ALS_4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating to determine the best lambda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_businesses = [x['business_id'] for x in valid_set]\n",
    "valid_users = [x['user_id'] for x in valid_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "c = Counter()\n",
    "c = Counter(valid_businesses)\n",
    "d = Counter()\n",
    "d = Counter(valid_users)\n",
    "keep_business = [item for item in c if c[item] > 20 ]\n",
    "keep_users = [item for item in d if d[item] > 20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we have an extremely small set to expedite the process of validating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_trimmed = [x for x in valid_set if x['business_id'] in keep_business and x['user_id'] in keep_users]\n",
    "valid_trimmed_df = pd.DataFrame(valid_trimmed)\n",
    "valid_trimmed_df.shape\n",
    "valid_scores = {(x['user_id'], x['business_id']): x['stars'] for x in valid_trimmed}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p3YqOYELqXtLyHz9T49p_w</td>\n",
       "      <td>2</td>\n",
       "      <td>-50XWnmQGqBgEI-9ANvLlg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3BCsAgo_1i4xMuTyLKMLRQ</td>\n",
       "      <td>3</td>\n",
       "      <td>-50XWnmQGqBgEI-9ANvLlg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wuQDMDlqM17jQNo0lYQZ7g</td>\n",
       "      <td>5</td>\n",
       "      <td>-50XWnmQGqBgEI-9ANvLlg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>g8oxQ1Ji9mr9PMjhEfaWSg</td>\n",
       "      <td>4</td>\n",
       "      <td>-50XWnmQGqBgEI-9ANvLlg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9a3DrZvpYxVs3k_qwlCNSw</td>\n",
       "      <td>5</td>\n",
       "      <td>-RhRXVW9z9fs5zzxhFfnHg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id  stars                 user_id\n",
       "0  p3YqOYELqXtLyHz9T49p_w      2  -50XWnmQGqBgEI-9ANvLlg\n",
       "1  3BCsAgo_1i4xMuTyLKMLRQ      3  -50XWnmQGqBgEI-9ANvLlg\n",
       "2  wuQDMDlqM17jQNo0lYQZ7g      5  -50XWnmQGqBgEI-9ANvLlg\n",
       "3  g8oxQ1Ji9mr9PMjhEfaWSg      4  -50XWnmQGqBgEI-9ANvLlg\n",
       "4  9a3DrZvpYxVs3k_qwlCNSw      5  -RhRXVW9z9fs5zzxhFfnHg"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_trimmed_df.sort_values(by = ['user_id']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratings_by_restaurant_valid = {}\n",
    "ratings_by_user_valid = {}\n",
    "\n",
    "for i in range(len(valid_trimmed_df)):\n",
    "    row = valid_trimmed_df.iloc[i]\n",
    "    bus_id = row[0]\n",
    "    stars = row[1]\n",
    "    user_id = row[2]\n",
    "    if bus_id not in ratings_by_restaurant_valid:\n",
    "        ratings_by_restaurant_valid[bus_id] = {user_id : stars}\n",
    "    else:\n",
    "        ratings_by_restaurant_valid[bus_id][user_id] = stars\n",
    "        \n",
    "    if user_id not in ratings_by_user_valid:\n",
    "        ratings_by_user_valid[user_id] = {bus_id : stars}\n",
    "    else:\n",
    "        ratings_by_user_valid[user_id][bus_id] = stars\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_sum_user_CV(tuning_vector, user, LAMBDA, q_item_CV, p_user_CV):\n",
    "    user_vector = tuning_vector\n",
    "    uv_mag = np.linalg.norm(user_vector)\n",
    "    summation = 0\n",
    "    for restaurant in ratings_by_user_valid[user]:\n",
    "        item_vector = q_item_CV[restaurant]\n",
    "        rv_mag = np.linalg.norm(item_vector)\n",
    "        term = np.dot(user_vector, item_vector) \n",
    "        user_dev = user_deviations[user]\n",
    "        item_dev = restaurant_deviations[restaurant]\n",
    "        error = (ratings_by_user_valid[user][restaurant] - global_review_average - term - user_dev - item_dev) ** 2 \n",
    "        + LAMBDA * (uv_mag **2 + rv_mag ** 2 + user_dev ** 2 + item_dev ** 2)\n",
    "        summation += error\n",
    "    return summation\n",
    "\n",
    "def minimize_user_vectors_CV(LAMBDA, q_item_CV, p_user_CV):\n",
    "    convergence = 0\n",
    "    for user in ratings_by_user_valid:\n",
    "        tuning_sums = []\n",
    "        for tuning_vector in tuning_vectors:\n",
    "            tuning_sum = calculate_sum_user_CV(tuning_vector, user, LAMBDA, q_item_CV, p_user_CV)\n",
    "            tuning_sums.append((tuning_vector, tuning_sum))\n",
    "        best = (min(tuning_sums, key = lambda x: x[1])[0])\n",
    "        difference = abs(best[0] - p_user_CV[user][0]) + abs(best[1] - p_user_CV[user][1])\n",
    "        + abs(best[2] - p_user_CV[user][2]) + abs(best[3] - p_user_CV[user][3])\n",
    "        p_user_CV[user] = best\n",
    "        convergence += difference\n",
    "    return convergence\n",
    "\n",
    "def calculate_sum_item_CV(tuning_vector, item, LAMBDA, q_item_CV, p_user_CV):\n",
    "    item_vector = tuning_vector\n",
    "    rv_mag = np.linalg.norm(item_vector)\n",
    "    summation = 0\n",
    "    for user in ratings_by_restaurant_valid[item]:\n",
    "        user_vector = p_user_CV[user]\n",
    "        uv_mag = np.linalg.norm(user_vector)\n",
    "        term = np.dot(item_vector, user_vector) \n",
    "        user_dev = user_deviations[user]\n",
    "        item_dev = restaurant_deviations[item]\n",
    "        error = (ratings_by_restaurant_valid[item][user] - global_review_average - user_dev - item_dev - term) ** 2 \n",
    "        + LAMBDA * (uv_mag **2 + rv_mag ** 2 + user_dev ** 2 + item_dev ** 2)\n",
    "        summation += error\n",
    "    return summation\n",
    "\n",
    "\n",
    "def minimize_item_vectors_CV(LAMBDA, q_item_CV, p_user_CV):\n",
    "    convergence = 0\n",
    "    for item in ratings_by_restaurant_valid:\n",
    "        tuning_sums = []\n",
    "        for tuning_vector in tuning_vectors:\n",
    "            tuning_sum = calculate_sum_item_CV(tuning_vector, item, LAMBDA, q_item_CV, p_user_CV)\n",
    "            tuning_sums.append((tuning_vector, tuning_sum))\n",
    "        best = (min(tuning_sums, key = lambda x: x[1])[0])\n",
    "        difference = abs(best[0] - q_item_CV[item][0]) + abs(best[1] - q_item_CV[item][1]) \n",
    "        + abs(best[2] - q_item_CV[item][2]) + abs(best[3] - q_item_CV[item][3])\n",
    "        q_item_CV[item] = best\n",
    "        convergence += difference\n",
    "    return convergence\n",
    "                     \n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ALS_CV(q_item_CV, p_user_CV, LAMBDA):\n",
    "    print ('optimizing item vectors')\n",
    "    convergence = minimize_item_vectors_CV(LAMBDA, q_item_CV, p_user_CV)\n",
    "    print (convergence)\n",
    "    while convergence > 5:\n",
    "        print ('optimizing user vectors')\n",
    "        convergence = minimize_user_vectors_CV(LAMBDA, q_item_CV, p_user_CV)\n",
    "        print (convergence)\n",
    "        print ('optimizing item vectors')\n",
    "        convergence = minimize_item_vectors_CV(LAMBDA, q_item_CV, p_user_CV)\n",
    "        print (convergence)\n",
    "    return q_item_CV, p_user_CV\n",
    "\n",
    "def predict(p_user_CV, q_item_CV, user_id, business_id):\n",
    "    user_dev = user_deviations[user_id]\n",
    "    item_dev = restaurant_deviations[business_id]\n",
    "    latent_term = np.dot(p_user_CV[user_id], q_item_CV[business_id]) \n",
    "    #print (latent_term)\n",
    "    prediction = global_review_average + user_dev + item_dev + latent_term\n",
    "    return int(round(prediction))\n",
    "\n",
    "def score_CV(q_item_CV, p_user_CV, LAMBDA, df):\n",
    "    predictions = []\n",
    "    for j in range(len(df)):\n",
    "        row = df.iloc[j]\n",
    "        business_id = row[0]\n",
    "        user_id = row[2]\n",
    "        pred = predict(p_user_CV, q_item_CV, user_id, business_id)\n",
    "        #print (pred)\n",
    "        predictions.append(pred)\n",
    "    print (predictions)\n",
    "    actual = df['stars']\n",
    "    df['validation_{}'.format(LAMBDA)] = predictions\n",
    "    return metrics.accuracy_score(actual, predictions)\n",
    "        \n",
    "def validate(LAMBDA):\n",
    "    q_item_CV = {}\n",
    "    p_user_CV = {}\n",
    "    for r in ratings_by_restaurant_valid:\n",
    "        q_item_CV[r] = [randrange(1,10)/10 for _ in range(4)]\n",
    "    for u in ratings_by_user_valid:\n",
    "        p_user_CV[u] = [randrange(1,10)/10 for _ in range(4)]\n",
    "    best_q_item, best_p_user = ALS_CV(q_item_CV, p_user_CV, LAMBDA)\n",
    "    score = score_CV(best_q_item, best_p_user, LAMBDA, valid_trimmed_df)\n",
    "    return score\n",
    "\n",
    "def run_validation(LAMBDAS):\n",
    "    validation_scores = {}\n",
    "    for LAMBDA in LAMBDAS:\n",
    "        print (LAMBDA)\n",
    "        score = validate(LAMBDA)\n",
    "        print ('score', score)\n",
    "        validation_scores[LAMBDA] = score\n",
    "    return validation_scores\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAMBDAS = [0.001, 0.01, 0.1, 1, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "optimizing item vectors\n",
      "78.89999999999999\n",
      "optimizing user vectors\n",
      "84.80000000000003\n",
      "optimizing item vectors\n",
      "16.700000000000003\n",
      "optimizing user vectors\n",
      "9.0\n",
      "optimizing item vectors\n",
      "3.8000000000000007\n",
      "[4, 5, 4, 4, 5, 4, 4, 3, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 4, 5, 5, 3, 5, 4, 4, 4, 4, 3, 4, 4, 5, 4, 4, 4, 5, 4, 4, 4, 5, 5, 5, 4, 3, 3, 4, 4, 4, 5, 4, 4, 5, 5, 5, 4, 5, 5, 5, 5, 4, 5, 4, 4, 4, 4, 3, 5, 5, 5, 3, 5, 4, 5, 5, 5, 4, 5, 5, 5, 5, 5, 4, 5, 4, 4, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 5, 4, 3, 5, 5, 5, 4, 4, 5, 4, 5, 4, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 5, 5, 4, 3, 4, 5, 4, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 5, 4, 5, 5, 3, 3, 4, 3, 4, 4, 4, 4, 4, 5, 4, 5, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 4, 4, 5, 5, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 5, 4, 4, 3, 3, 5, 3, 4, 4, 4, 3, 4, 4, 5, 4, 3, 5, 5, 5, 5, 5, 5, 5, 5, 4, 5, 4, 4, 4, 3, 4, 5, 4, 5, 4, 3, 4, 3, 5, 4, 5, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 5, 5, 3, 4, 4, 4, 4, 5, 4, 5, 4, 5, 4, 3, 5, 4, 4, 5, 4, 4, 4, 5, 5, 5, 4, 4, 4, 5, 5, 4, 5, 5, 3, 4, 5, 4, 4, 4, 5, 4, 4, 5, 5]\n",
      "score 0.59477124183\n",
      "0.01\n",
      "optimizing item vectors\n",
      "74.6\n",
      "optimizing user vectors\n",
      "89.89999999999998\n",
      "optimizing item vectors\n",
      "17.0\n",
      "optimizing user vectors\n",
      "5.4\n",
      "optimizing item vectors\n",
      "6.3\n",
      "optimizing user vectors\n",
      "2.7000000000000006\n",
      "optimizing item vectors\n",
      "2.8\n",
      "[4, 5, 4, 4, 5, 4, 4, 3, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 4, 5, 5, 3, 5, 4, 4, 4, 4, 3, 4, 4, 5, 4, 4, 4, 5, 4, 4, 4, 5, 5, 5, 4, 3, 3, 4, 4, 4, 5, 4, 4, 5, 5, 5, 4, 5, 5, 5, 5, 4, 5, 4, 4, 4, 4, 3, 5, 5, 5, 3, 5, 4, 5, 5, 5, 4, 5, 5, 5, 5, 5, 4, 5, 4, 4, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 5, 4, 3, 5, 5, 5, 4, 4, 5, 4, 5, 4, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 5, 5, 4, 3, 4, 5, 4, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 5, 4, 5, 5, 3, 3, 4, 3, 4, 4, 4, 4, 4, 5, 4, 5, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 4, 4, 5, 5, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 5, 4, 4, 3, 3, 5, 3, 4, 4, 4, 3, 4, 4, 5, 4, 3, 5, 5, 5, 5, 5, 5, 5, 5, 4, 5, 4, 4, 4, 3, 5, 5, 4, 5, 4, 3, 4, 3, 5, 4, 5, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 5, 5, 3, 4, 4, 4, 4, 5, 4, 5, 4, 5, 4, 3, 5, 4, 4, 5, 4, 4, 4, 5, 5, 5, 4, 4, 4, 5, 5, 4, 5, 5, 3, 4, 5, 4, 4, 4, 5, 4, 4, 5, 5]\n",
      "score 0.598039215686\n",
      "0.1\n",
      "optimizing item vectors\n",
      "70.5\n",
      "optimizing user vectors\n",
      "90.80000000000004\n",
      "optimizing item vectors\n",
      "18.900000000000002\n",
      "optimizing user vectors\n",
      "5.699999999999999\n",
      "optimizing item vectors\n",
      "5.199999999999999\n",
      "optimizing user vectors\n",
      "3.1000000000000005\n",
      "optimizing item vectors\n",
      "0.9999999999999999\n",
      "[4, 5, 4, 4, 5, 4, 4, 3, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 4, 5, 5, 3, 5, 3, 4, 4, 4, 3, 4, 4, 5, 4, 4, 4, 5, 4, 4, 4, 5, 5, 5, 4, 3, 3, 4, 4, 4, 5, 4, 4, 5, 5, 5, 4, 5, 5, 5, 5, 4, 5, 4, 4, 4, 4, 3, 5, 5, 5, 3, 5, 4, 5, 5, 5, 4, 5, 5, 5, 5, 5, 4, 5, 4, 4, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 5, 4, 3, 5, 5, 5, 4, 4, 5, 4, 5, 4, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 5, 5, 4, 3, 4, 5, 4, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 5, 4, 5, 5, 3, 3, 4, 3, 4, 4, 4, 4, 4, 5, 4, 5, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 4, 4, 5, 5, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 5, 4, 4, 3, 3, 5, 3, 4, 4, 4, 3, 4, 4, 5, 4, 3, 5, 5, 5, 5, 5, 5, 5, 5, 4, 5, 4, 4, 4, 3, 4, 5, 4, 5, 4, 3, 4, 3, 5, 4, 5, 4, 4, 4, 5, 4, 4, 4, 4, 4, 5, 5, 4, 5, 5, 4, 5, 5, 3, 4, 4, 4, 4, 5, 4, 5, 4, 5, 4, 3, 5, 4, 4, 5, 4, 4, 4, 5, 5, 5, 4, 4, 4, 5, 5, 4, 5, 5, 3, 4, 5, 4, 4, 5, 5, 4, 4, 5, 5]\n",
      "score 0.598039215686\n",
      "1\n",
      "optimizing item vectors\n",
      "73.7\n",
      "optimizing user vectors\n",
      "98.00000000000003\n",
      "optimizing item vectors\n",
      "16.099999999999998\n",
      "optimizing user vectors\n",
      "9.600000000000001\n",
      "optimizing item vectors\n",
      "6.6000000000000005\n",
      "optimizing user vectors\n",
      "4.8\n",
      "optimizing item vectors\n",
      "2.9000000000000004\n",
      "[4, 5, 4, 4, 5, 4, 4, 3, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 4, 5, 5, 3, 5, 4, 4, 4, 4, 3, 4, 4, 5, 4, 4, 4, 5, 4, 4, 4, 5, 5, 5, 4, 3, 3, 4, 4, 4, 5, 4, 4, 5, 5, 5, 4, 5, 5, 5, 5, 4, 5, 4, 4, 4, 4, 3, 5, 5, 5, 3, 5, 4, 5, 5, 5, 4, 5, 5, 5, 5, 5, 4, 5, 4, 4, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 5, 4, 3, 5, 5, 5, 4, 4, 5, 4, 5, 4, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 5, 5, 4, 3, 4, 5, 4, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 5, 4, 5, 5, 3, 3, 4, 3, 4, 4, 4, 4, 4, 5, 4, 5, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 4, 4, 5, 5, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 5, 4, 4, 3, 3, 5, 3, 4, 4, 4, 3, 4, 4, 5, 4, 3, 5, 5, 5, 5, 5, 5, 5, 5, 4, 5, 4, 4, 4, 3, 4, 5, 4, 5, 4, 3, 4, 3, 5, 4, 5, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 5, 5, 3, 4, 4, 4, 4, 5, 4, 5, 4, 5, 4, 3, 5, 4, 4, 5, 4, 4, 4, 5, 5, 5, 4, 4, 4, 5, 5, 4, 5, 5, 3, 4, 5, 4, 4, 5, 5, 4, 4, 5, 5]\n",
      "score 0.598039215686\n",
      "10\n",
      "optimizing item vectors\n",
      "75.0\n",
      "optimizing user vectors\n",
      "91.70000000000002\n",
      "optimizing item vectors\n",
      "15.599999999999998\n",
      "optimizing user vectors\n",
      "7.800000000000001\n",
      "optimizing item vectors\n",
      "5.900000000000001\n",
      "optimizing user vectors\n",
      "1.8000000000000003\n",
      "optimizing item vectors\n",
      "1.6\n",
      "[4, 5, 4, 4, 5, 4, 4, 3, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 4, 5, 5, 3, 5, 3, 4, 4, 4, 3, 4, 4, 5, 4, 4, 4, 5, 4, 4, 4, 5, 5, 5, 4, 3, 3, 4, 4, 4, 5, 4, 4, 5, 5, 5, 4, 5, 5, 5, 5, 4, 5, 4, 4, 4, 4, 3, 5, 5, 5, 3, 5, 4, 5, 5, 5, 4, 5, 5, 5, 5, 5, 4, 5, 4, 4, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 5, 4, 3, 5, 5, 5, 4, 4, 5, 4, 5, 4, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 5, 5, 4, 3, 4, 5, 4, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 5, 5, 5, 5, 3, 3, 4, 3, 4, 4, 4, 4, 4, 5, 4, 5, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 4, 4, 5, 5, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 5, 4, 4, 3, 3, 5, 3, 4, 4, 4, 3, 4, 4, 5, 4, 3, 5, 5, 5, 5, 5, 5, 5, 5, 4, 5, 4, 4, 4, 3, 4, 5, 4, 5, 4, 3, 4, 3, 5, 4, 5, 4, 4, 4, 5, 4, 4, 4, 4, 4, 5, 5, 4, 5, 5, 4, 5, 5, 3, 4, 4, 4, 4, 5, 4, 5, 4, 5, 4, 3, 5, 4, 4, 5, 4, 4, 4, 5, 5, 5, 4, 4, 4, 5, 5, 4, 5, 5, 3, 4, 5, 4, 4, 5, 5, 4, 4, 5, 5]\n",
      "score 0.601307189542\n"
     ]
    }
   ],
   "source": [
    "run_validation(LAMBDAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_scores = {0.001:0.59477124183, 0.01: 0.598039215686, 0.1: 0.598039215686,\n",
    "                     1: 0.598039215686,10: 0.601307189542}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.001: 0.59477124183,\n",
       " 0.01: 0.598039215686,\n",
       " 0.1: 0.598039215686,\n",
       " 1: 0.598039215686,\n",
       " 10: 0.601307189542}"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_predict(user_id, business_id):\n",
    "    user_dev = user_deviations[user_id]\n",
    "    item_dev = restaurant_deviations[business_id]\n",
    "    latent_term = 0\n",
    "    if user_id in p_user:\n",
    "        if business_id in q_item:\n",
    "            latent_term = np.dot(p_user[user_id], q_item[business_id]) \n",
    "    prediction = global_review_average + user_dev + item_dev + latent_term\n",
    "    #print (prediction)\n",
    "    return int(round(prediction))\n",
    "\n",
    "def predict_all(df):\n",
    "    predictions = []\n",
    "    for j in range(len(df)):\n",
    "        row = df.iloc[j]\n",
    "        business_id = row[0]\n",
    "        user_id = row[2]\n",
    "        pred = model_predict(user_id, business_id)\n",
    "        predictions.append(pred)\n",
    "    df['pred'] = predictions\n",
    "    return metrics.accuracy_score(df['stars'], df['pred'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the latent factors on the train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy on the train set using latent factors is 0.6136\n"
     ]
    }
   ],
   "source": [
    "train_pred = pd.DataFrame(trimmed_train)\n",
    "train_score = predict_all(train_pred)\n",
    "print ('The accuracy on the train set using latent factors is {}'.format(train_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy on the test set using latent factors is 0.39599813866914846\n"
     ]
    }
   ],
   "source": [
    "test_set_v2 = [x for x in test_set if x['business_id'] in q_item and x['user_id'] in p_user]\n",
    "test_df_v2 = pd.DataFrame(test_set_v2)\n",
    "test_score = predict_all(test_df_v2)\n",
    "print ('The accuracy on the test set using latent factors is {}'.format(test_score))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
